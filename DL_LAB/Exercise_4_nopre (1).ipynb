{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1d877c1-26b4-46d4-932e-6a4482d33baf",
   "metadata": {},
   "source": [
    "### Implement word embeddings for IMDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd8cdb4-c04f-4f1c-b224-5ee4ffe40e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41536ed4-579a-4f60-a650-79036096a413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDB dataset (restrict vocabulary to 10,000 most frequent words)\n",
    "num_words = 10000  # Vocabulary size limit\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f47c6588-73a7-41fe-9345-a584dc1df60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to a fixed length\n",
    "max_length = 200\n",
    "x_train = pad_sequences(x_train, maxlen=max_length)\n",
    "x_test = pad_sequences(x_test, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4be4490c-2765-40ee-9aa4-d976138f83de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vocabulary size correctly\n",
    "vocab_size = num_words  # Fix vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2700bde2-0734-443f-b8da-7ba18704e1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akanksh_02\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Build a simple neural network with an embedding layer\n",
    "embedding_dim = 50\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f5ad1eb-3b48-49da-aeee-946233e5ba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49d48e39-b259-462e-981d-914f526c7ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4508a59e-1b77-4e01-8d51-70cac76387ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6799 - loss: 0.5662\n",
      "Epoch 2/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9236 - loss: 0.2058\n",
      "Epoch 3/3\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9770 - loss: 0.0938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2b57bd33da0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=32)  # Train for a small number of epochs for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6849e97-31d6-41c4-be38-9e97524ea297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8677 - loss: 0.3245\n",
      "Test Accuracy: 86.81%\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Evaluate Model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "454dfbe4-594d-4a88-9139-6f3dd565dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the learned word embeddings\n",
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]  # Shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c335b9dc-6790-49e3-b93e-1798c4f242e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDB word index and **correctly align indices**\n",
    "imdb_word_index = imdb.get_word_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6295cd7-c3ef-47ae-b9a8-ea47f833bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct word index **as per load_data() conventions**\n",
    "word_index = {word: (index + 3) for word, index in imdb_word_index.items()}  # Shift indices by 3\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04f0612c-3467-424a-8811-5b74cb25af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse lookup dictionary for saving embeddings\n",
    "reverse_word_index = {i: word for word, i in word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f8aaf03-6f3b-4609-93ae-b7273f2f8c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Printing reverse word index first few items\n",
      "\n",
      "<PAD>   <START>   <UNK>   <UNUSED>\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPrinting reverse word index first few items\\n\")\n",
    "print(reverse_word_index.get(0), \" \", reverse_word_index.get(1), \" \", reverse_word_index.get(2), \" \", reverse_word_index.get(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25d4de1a-f3c4-4b5a-8cfc-1ac81a1a7478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word embeddings saved to word_embeddings.txt\n"
     ]
    }
   ],
   "source": [
    "# Save the learned word embeddings correctly\n",
    "with open(\"4_word_embeddings.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    for i in range(1, vocab_size):  # Skip padding index (0)\n",
    "        word = reverse_word_index.get(i, \"<UNK>\")  # Use <UNK> for missing words\n",
    "        embedding = \" \".join(map(str, weights[i]))  # Convert embedding to space-separated string\n",
    "        file.write(f\"{word} {embedding}\\n\")\n",
    "\n",
    "print(\"Word embeddings saved to word_embeddings.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cec4c6-5f17-43e8-abe7-fafd7a630de1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
